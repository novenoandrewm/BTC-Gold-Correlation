{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44f7f95",
   "metadata": {},
   "source": [
    "1. Setup & Target Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57dfd4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files: ['gold_monthly_clean_2020_2025.csv', 'btc_monthly_close_2020_2025.csv', 'merged_gold_btc_monthly_2020_2025.csv', 'monthly_returns_gold_btc_2020_2025.csv']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook 10 – Data Dictionary (Processed)\n",
    "Goal:\n",
    "- Mensintesis kamus data untuk seluruh CSV di data/processed.\n",
    "- QC ringkas per dataset (range EOM 2020–2025, missing, duplikasi index).\n",
    "- Menulis keluaran ke CSV + Markdown (opsional).\n",
    "\n",
    "Note on tooling:\n",
    "- Beberapa boilerplate dibantu oleh ChatGPT (GPT-5 Thinking); semua hasil sudah diverifikasi dan disesuaikan manual.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_any_dtype\n",
    "\n",
    "PROC = Path(\"data/processed\")\n",
    "TBL  = Path(\"reports/tables\");  TBL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILES = [\n",
    "    PROC/\"gold_monthly_clean_2020_2025.csv\",\n",
    "    PROC/\"btc_monthly_close_2020_2025.csv\",\n",
    "    PROC/\"merged_gold_btc_monthly_2020_2025.csv\",\n",
    "    PROC/\"monthly_returns_gold_btc_2020_2025.csv\",\n",
    "]\n",
    "\n",
    "# add all other processed CSVs (avoid duplicates & non-existent files)\n",
    "seen = {p.resolve() for p in FILES}\n",
    "for extra in PROC.glob(\"*.csv\"):\n",
    "    if extra.resolve() not in seen and extra.exists():\n",
    "        FILES.append(extra)\n",
    "\n",
    "FILES = [p for p in FILES if p.exists()]\n",
    "print(\"Processed files:\", [f.name for f in FILES])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07393a85",
   "metadata": {},
   "source": [
    "2. Function Profiler (Column & Dataset-Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0a7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_role(col: str) -> str:\n",
    "    c = col.lower()\n",
    "    if c == \"date\": return \"key(time)\"\n",
    "    if \"ret\" in c:  return \"feature(return)\"\n",
    "    if \"usd\" in c:  return \"feature(level)\"\n",
    "    return \"feature\"\n",
    "\n",
    "def _infer_unit(col: str) -> str:\n",
    "    c = col.lower()\n",
    "    if c == \"date\": return \"YYYY-MM (EOM)\"\n",
    "    if \"ret\" in c:  return \"log return (unitless)\"\n",
    "    if \"usd\" in c:  return \"USD\"\n",
    "    return \"\"\n",
    "\n",
    "def _infer_desc(file: str, col: str) -> str:\n",
    "    f = file.lower()\n",
    "    c = col.lower()\n",
    "    if c == \"date\": return \"End-of-month timestamp (EOM)\"\n",
    "    if f.startswith(\"gold\") and c == \"gold_usd\":\n",
    "        return \"Monthly gold price (USD), end-of-month close\"\n",
    "    if f.startswith(\"btc\") and c == \"btc_usd\":\n",
    "        return \"Monthly Bitcoin price (USD), end-of-month close\"\n",
    "    if \"merged\" in f and c in (\"gold_usd\",\"btc_usd\"):\n",
    "        return f\"Merged {col} at EOM\"\n",
    "    if \"returns\" in f and \"ret\" in c:\n",
    "        base = col.split(\"_\")[0].title()\n",
    "        return f\"Month-over-month log return of {base}\"\n",
    "    return \"\"\n",
    "\n",
    "def profile_file(path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Return (columns_profile, dataset_profile) for a CSV in processed/.\n",
    "    - Normalizes 'Date' to EOM if present.\n",
    "    - Computes column stats + dataset coverage w.r.t. 2020-01..2025-12.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Time index normalization\n",
    "    if \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        df = df.set_index(\"Date\").sort_index()\n",
    "        if isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = df.index.to_period(\"M\").to_timestamp(\"M\")\n",
    "\n",
    "    # ---- Column-level ----\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    # column order: show Date first if available\n",
    "    ordered_cols = ([\"Date\"] if \"Date\" in df.reset_index().columns else []) + [c for c in df.columns if c != \"Date\"]\n",
    "\n",
    "    for col in ordered_cols:\n",
    "        if col == \"Date\" and isinstance(df.index, pd.DatetimeIndex):\n",
    "            s = df.index.to_series(name=\"Date\")\n",
    "        else:\n",
    "            s = (df[col] if col in df.columns else df.reset_index()[col])\n",
    "\n",
    "        dtype    = str(s.dtype)\n",
    "        non_null = int(s.notna().sum())\n",
    "        nulls    = int(s.isna().sum())\n",
    "        distinct = int(s.nunique(dropna=True))\n",
    "        example  = s.dropna().iloc[0] if non_null else np.nan\n",
    "\n",
    "        # safe min/max\n",
    "        if is_numeric_dtype(s):\n",
    "            vmin = float(np.nanmin(s.values)) if non_null else np.nan\n",
    "            vmax = float(np.nanmax(s.values)) if non_null else np.nan\n",
    "        elif is_datetime64_any_dtype(s):\n",
    "            vmin = pd.to_datetime(s.min()) if non_null else pd.NaT\n",
    "            vmax = pd.to_datetime(s.max()) if non_null else pd.NaT\n",
    "        else:\n",
    "            vmin = vmax = np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": path.name,\n",
    "            \"column\": col,\n",
    "            \"dtype\": dtype,\n",
    "            \"non_null\": non_null,\n",
    "            \"nulls\": nulls,\n",
    "            \"distinct\": distinct,\n",
    "            \"min\": vmin,\n",
    "            \"max\": vmax,\n",
    "            \"example\": example,\n",
    "            \"unit\": _infer_unit(col),\n",
    "            \"role\": _infer_role(col),\n",
    "            \"description\": _infer_desc(path.name, col),\n",
    "            \"source\": \"Processed (pipeline steps 02–07)\",\n",
    "            \"transform\": (\n",
    "                \"Hourly→EOM monthly close\" if \"btc\" in path.name.lower() else\n",
    "                \"Monthly EOM; cleaned & filtered 2020–2025\" if \"gold\" in path.name.lower() else\n",
    "                \"Inner-join on EOM index\" if \"merged\" in path.name.lower() else\n",
    "                \"Log returns (Δ ln level)\" if \"returns\" in path.name.lower() else\n",
    "                \"\"\n",
    "            )\n",
    "        })\n",
    "\n",
    "    columns_profile = pd.DataFrame(rows)\n",
    "\n",
    "    # ---- Dataset-level ----\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        start, end = df.index.min(), df.index.max()\n",
    "        eom_expected = pd.period_range(\"2020-01\", \"2025-12\", freq=\"M\").to_timestamp(\"M\")\n",
    "        present = pd.Index(df.index.unique()).sort_values()\n",
    "        missing = eom_expected.difference(present)\n",
    "        coverage_rate = round(100.0 * (len(eom_expected) - len(missing)) / len(eom_expected), 2)\n",
    "        dupe_idx = int(pd.Index(df.index).duplicated().sum())\n",
    "    else:\n",
    "        start = end = pd.NaT\n",
    "        missing = pd.DatetimeIndex([])\n",
    "        coverage_rate = np.nan\n",
    "        dupe_idx = 0\n",
    "\n",
    "    dataset_profile = pd.DataFrame([{\n",
    "        \"file\": path.name,\n",
    "        \"rows\": len(df),\n",
    "        \"n_cols\": df.shape[1],\n",
    "        \"start\": start if pd.notna(start) else \"\",\n",
    "        \"end\": end if pd.notna(end) else \"\",\n",
    "        \"eom_missing\": int(len(missing)),\n",
    "        \"coverage_%\": coverage_rate,\n",
    "        \"dup_index\": dupe_idx\n",
    "    }])\n",
    "\n",
    "    return columns_profile, dataset_profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d7409",
   "metadata": {},
   "source": [
    "3. Build Data Dictionaries + Combine Records Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977f2f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                     file    column           dtype  non_null  \\\n",
       " 0         btc_monthly_close_2020_2025.csv   BTC_USD         float64        70   \n",
       " 1         btc_monthly_close_2020_2025.csv      Date  datetime64[ns]        70   \n",
       " 2        gold_monthly_clean_2020_2025.csv  Gold_USD         float64        67   \n",
       " 3        gold_monthly_clean_2020_2025.csv      Date  datetime64[ns]        67   \n",
       " 4   merged_gold_btc_monthly_2020_2025.csv   BTC_USD         float64        67   \n",
       " 5   merged_gold_btc_monthly_2020_2025.csv  Gold_USD         float64        67   \n",
       " 6   merged_gold_btc_monthly_2020_2025.csv      Date  datetime64[ns]        67   \n",
       " 7  monthly_returns_gold_btc_2020_2025.csv   BTC_USD         float64        66   \n",
       " \n",
       "    nulls  distinct                  min                  max  \\\n",
       " 0      0        70              6423.61             116009.4   \n",
       " 1      0        70  2020-01-31 00:00:00  2025-10-31 00:00:00   \n",
       " 2      0        67              1560.67              3352.66   \n",
       " 3      0        67  2020-01-31 00:00:00  2025-07-31 00:00:00   \n",
       " 4      0        67              6423.61             116009.4   \n",
       " 5      0        67              1560.67              3352.66   \n",
       " 6      0        67  2020-01-31 00:00:00  2025-07-31 00:00:00   \n",
       " 7      0        66              6423.61             116009.4   \n",
       " \n",
       "                example           unit            role  \\\n",
       " 0              9342.23            USD  feature(level)   \n",
       " 1  2020-01-31 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " 2              1560.67            USD  feature(level)   \n",
       " 3  2020-01-31 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " 4              9342.23            USD  feature(level)   \n",
       " 5              1560.67            USD  feature(level)   \n",
       " 6  2020-01-31 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " 7              8545.45            USD  feature(level)   \n",
       " \n",
       "                                        description  \\\n",
       " 0  Monthly Bitcoin price (USD), end-of-month close   \n",
       " 1                     End-of-month timestamp (EOM)   \n",
       " 2     Monthly gold price (USD), end-of-month close   \n",
       " 3                     End-of-month timestamp (EOM)   \n",
       " 4                            Merged BTC_USD at EOM   \n",
       " 5                           Merged Gold_USD at EOM   \n",
       " 6                     End-of-month timestamp (EOM)   \n",
       " 7                                                    \n",
       " \n",
       "                              source                                  transform  \n",
       " 0  Processed (pipeline steps 02–07)                   Hourly→EOM monthly close  \n",
       " 1  Processed (pipeline steps 02–07)                   Hourly→EOM monthly close  \n",
       " 2  Processed (pipeline steps 02–07)  Monthly EOM; cleaned & filtered 2020–2025  \n",
       " 3  Processed (pipeline steps 02–07)  Monthly EOM; cleaned & filtered 2020–2025  \n",
       " 4  Processed (pipeline steps 02–07)                   Hourly→EOM monthly close  \n",
       " 5  Processed (pipeline steps 02–07)                   Hourly→EOM monthly close  \n",
       " 6  Processed (pipeline steps 02–07)                   Hourly→EOM monthly close  \n",
       " 7  Processed (pipeline steps 02–07)                   Hourly→EOM monthly close  ,\n",
       "                                      file  rows  n_cols      start        end  \\\n",
       " 0         btc_monthly_close_2020_2025.csv    70       1 2020-01-31 2025-10-31   \n",
       " 1        gold_monthly_clean_2020_2025.csv    67       1 2020-01-31 2025-07-31   \n",
       " 2   merged_gold_btc_monthly_2020_2025.csv    67       2 2020-01-31 2025-07-31   \n",
       " 3  monthly_returns_gold_btc_2020_2025.csv    66       4 2020-02-29 2025-07-31   \n",
       " \n",
       "    eom_missing  coverage_%  dup_index  \n",
       " 0            2       97.22          0  \n",
       " 1            5       93.06          0  \n",
       " 2            5       93.06          0  \n",
       " 3            6       91.67          0  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols, all_ds = [], []\n",
    "for p in FILES:\n",
    "    cprof, dprof = profile_file(p)\n",
    "    all_cols.append(cprof)\n",
    "    all_ds.append(dprof)\n",
    "\n",
    "data_dict = pd.concat(all_cols, ignore_index=True)\n",
    "dataset_summary = pd.concat(all_ds, ignore_index=True)\n",
    "\n",
    "# Optional override of notes\n",
    "notes_path = TBL/\"data_dictionary_notes.csv\" \n",
    "if notes_path.exists():\n",
    "    notes = pd.read_csv(notes_path)\n",
    "    data_dict = data_dict.merge(notes, on=[\"file\",\"column\"], how=\"left\", suffixes=(\"\",\"_note\"))\n",
    "    for k in (\"description\",\"unit\",\"role\"):\n",
    "        if f\"{k}_note\" in data_dict.columns:\n",
    "            data_dict[k] = data_dict[f\"{k}_note\"].fillna(data_dict[k])\n",
    "            data_dict.drop(columns=[f\"{k}_note\"], inplace=True)\n",
    "\n",
    "# Tidy up\n",
    "data_dict = (data_dict\n",
    "             .sort_values([\"file\",\"role\",\"column\"], kind=\"stable\")\n",
    "             .reset_index(drop=True))\n",
    "dataset_summary = dataset_summary.sort_values(\"file\").reset_index(drop=True)\n",
    "\n",
    "data_dict.head(8), dataset_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7f375",
   "metadata": {},
   "source": [
    "4. Save CSV + Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352e1f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → C:\\Users\\Noveno\\OneDrive\\CA1-BTC-Gold-Correlation\\reports\\tables\\data_dictionary.csv\n",
      "Saved → C:\\Users\\Noveno\\OneDrive\\CA1-BTC-Gold-Correlation\\reports\\tables\\dataset_summary.csv\n",
      "Saved → C:\\Users\\Noveno\\OneDrive\\CA1-BTC-Gold-Correlation\\reports\\tables\\data_dictionary.md\n"
     ]
    }
   ],
   "source": [
    "# --- Save CSV ---\n",
    "dict_path = TBL/\"data_dictionary.csv\"\n",
    "sum_path  = TBL/\"dataset_summary.csv\"\n",
    "data_dict.to_csv(dict_path, index=False)\n",
    "dataset_summary.to_csv(sum_path, index=False)\n",
    "print(\"Saved →\", dict_path.resolve())\n",
    "print(\"Saved →\", sum_path.resolve())\n",
    "\n",
    "# --- Compact Markdown for Word/Report ---\n",
    "try:\n",
    "    import tabulate  # noqa: F401 # just to make sure it's available\n",
    "    md_lines = [\"# Data Dictionary (Processed)\\n\"]\n",
    "    for f, g in data_dict.groupby(\"file\"):\n",
    "        md_lines.append(f\"\\n## {f}\\n\")\n",
    "        sub = g[[\"column\",\"dtype\",\"unit\",\"role\",\"description\"]].copy()\n",
    "        md_lines.append(sub.to_markdown(index=False))\n",
    "    md = \"\\n\".join(md_lines)\n",
    "    md_path = TBL/\"data_dictionary.md\"\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as fh:\n",
    "        fh.write(md)\n",
    "    print(\"Saved →\", md_path.resolve())\n",
    "except Exception as e:\n",
    "    print(\"Skip Markdown (install tabulate to enable): pip install tabulate\")\n",
    "    print(\"Reason:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
