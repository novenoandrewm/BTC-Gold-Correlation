{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44f7f95",
   "metadata": {},
   "source": [
    "1. Setup & Target Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57dfd4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files: ['gold_monthly_clean_2020_2025.csv', 'btc_monthly_close_2020_2025.csv', 'merged_gold_btc_monthly_2020_2025.csv', 'monthly_returns_gold_btc_2020_2025.csv']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROC = Path(\"data/processed\")\n",
    "TBL  = Path(\"reports/tables\");  TBL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Default target (can add/subtract)\n",
    "FILES = [\n",
    "    PROC/\"gold_monthly_clean_2020_2025.csv\",\n",
    "    PROC/\"btc_monthly_close_2020_2025.csv\",\n",
    "    PROC/\"merged_gold_btc_monthly_2020_2025.csv\",\n",
    "    PROC/\"monthly_returns_gold_btc_2020_2025.csv\",\n",
    "]\n",
    "\n",
    "# Also fetch all other CSVs in processed (if any)\n",
    "for extra in PROC.glob(\"*.csv\"):\n",
    "    if extra not in FILES:\n",
    "        FILES.append(extra)\n",
    "\n",
    "print(\"Processed files:\", [f.name for f in FILES if f.exists()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07393a85",
   "metadata": {},
   "source": [
    "2. Function Profiler (Column & Dataset-Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0a7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "def _infer_role(col: str) -> str:\n",
    "    c = col.lower()\n",
    "    if c == \"date\": return \"key(time)\"\n",
    "    if \"ret\" in c:  return \"feature(return)\"\n",
    "    if \"usd\" in c:  return \"feature(level)\"\n",
    "    return \"feature\"\n",
    "\n",
    "def _infer_unit(col: str) -> str:\n",
    "    c = col.lower()\n",
    "    if c.endswith(\"_usd\") or \"usd\" in c: return \"USD\"\n",
    "    if \"ret\" in c: return \"log return (unitless)\"\n",
    "    if c == \"date\": return \"YYYY-MM (EOM)\"\n",
    "    return \"\"\n",
    "\n",
    "def _infer_desc(file: str, col: str) -> str:\n",
    "    f = file.lower()\n",
    "    c = col.lower()\n",
    "    if f.startswith(\"gold\") and c==\"gold_usd\": return \"Monthly gold price (USD), end-of-month close\"\n",
    "    if f.startswith(\"btc\")  and c==\"btc_usd\":  return \"Monthly BTC price (USD), end-of-month close\"\n",
    "    if \"merged\" in f and c in (\"gold_usd\",\"btc_usd\"): return f\"Merged {col} at EOM\"\n",
    "    if \"returns\" in f and \"ret\" in c: return f\"Log return of {col.split('_')[0].title()} (month-over-month)\"\n",
    "    if c==\"date\": return \"End-of-month timestamp (EOM)\"\n",
    "    return \"\"\n",
    "\n",
    "def profile_file(path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Return (columns_profile, dataset_profile).\"\"\"\n",
    "    # Parse Date if any\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        df = df.set_index(\"Date\").sort_index()\n",
    "        # Normalize to EOM if index is datetime\n",
    "        if isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = df.index.to_period(\"M\").to_timestamp(\"M\")\n",
    "\n",
    "    # Column-level\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for col in ([\"Date\"] if \"Date\" in df.reset_index().columns else []) + [c for c in df.columns if c!=\"Date\"]:\n",
    "        s = (df.reset_index()[col] if \"Date\" in df.index.names else df[col]) if col!=\"Date\" else df.index.to_series(name=\"Date\")\n",
    "        dtype = str(s.dtype)\n",
    "        non_null = int(s.notna().sum())\n",
    "        nulls    = int(s.isna().sum())\n",
    "        distinct = int(s.nunique(dropna=True))\n",
    "        example  = s.dropna().iloc[0] if non_null>0 else np.nan\n",
    "        # min/max for numeric or datetime\n",
    "        if np.issubdtype(s.dtype, np.number):\n",
    "            vmin = float(np.nanmin(s)) if non_null else np.nan\n",
    "            vmax = float(np.nanmax(s)) if non_null else np.nan\n",
    "        elif np.issubdtype(s.dtype, \"datetime64[ns]\"):\n",
    "            vmin = s.min()\n",
    "            vmax = s.max()\n",
    "        else:\n",
    "            vmin = vmax = np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": path.name,\n",
    "            \"column\": col,\n",
    "            \"dtype\": dtype,\n",
    "            \"non_null\": non_null,\n",
    "            \"nulls\": nulls,\n",
    "            \"distinct\": distinct,\n",
    "            \"min\": vmin,\n",
    "            \"max\": vmax,\n",
    "            \"example\": example,\n",
    "            \"unit\": _infer_unit(col),\n",
    "            \"role\": _infer_role(col),\n",
    "            \"description\": _infer_desc(path.name, col),   # boleh diedit manual nanti\n",
    "            \"source\": \"Processed (pipeline 02–07)\",\n",
    "            \"transform\": (\"Hourly→EOM monthly close\" if \"btc\" in path.name.lower()\n",
    "                          else \"Monthly EOM; cleaned & filtered 2020–2025\" if \"gold\" in path.name.lower()\n",
    "                          else \"Merged EOM\" if \"merged\" in path.name.lower()\n",
    "                          else \"Log returns (Δ ln level)\")\n",
    "        })\n",
    "\n",
    "    columns_profile = pd.DataFrame(rows)\n",
    "\n",
    "    # Compact dataset-level\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        start, end = (df.index.min(), df.index.max())\n",
    "        # EOM compliance\n",
    "        eom_expected = pd.period_range(\"2020-01\",\"2025-12\", freq=\"M\").to_timestamp(\"M\")\n",
    "        missing = eom_expected.difference(df.index)\n",
    "        dupe_idx = int(pd.Index(df.index).duplicated().sum())\n",
    "    else:\n",
    "        start = end = pd.NaT\n",
    "        missing = pd.DatetimeIndex([])\n",
    "        dupe_idx = 0\n",
    "\n",
    "    dataset_profile = pd.DataFrame([{\n",
    "        \"file\": path.name,\n",
    "        \"rows\": len(df),\n",
    "        \"n_cols\": df.shape[1],\n",
    "        \"start\": start if pd.notna(start) else \"\",\n",
    "        \"end\": end if pd.notna(end) else \"\",\n",
    "        \"eom_missing\": len(missing),\n",
    "        \"dup_index\": dupe_idx\n",
    "    }])\n",
    "\n",
    "    return columns_profile, dataset_profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d7409",
   "metadata": {},
   "source": [
    "3. Build Data Dictionaries + Combine Records Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977f2f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                     file    column           dtype  non_null  \\\n",
       " 0        gold_monthly_clean_2020_2025.csv      Date  datetime64[ns]        67   \n",
       " 1        gold_monthly_clean_2020_2025.csv  Gold_USD         float64        67   \n",
       " 2         btc_monthly_close_2020_2025.csv      Date  datetime64[ns]        70   \n",
       " 3         btc_monthly_close_2020_2025.csv   BTC_USD         float64        70   \n",
       " 4   merged_gold_btc_monthly_2020_2025.csv      Date  datetime64[ns]        67   \n",
       " 5   merged_gold_btc_monthly_2020_2025.csv  Gold_USD         float64        67   \n",
       " 6   merged_gold_btc_monthly_2020_2025.csv   BTC_USD         float64        67   \n",
       " 7  monthly_returns_gold_btc_2020_2025.csv      Date  datetime64[ns]        66   \n",
       " \n",
       "    nulls  distinct                  min                  max  \\\n",
       " 0      0        67  2020-01-31 00:00:00  2025-07-31 00:00:00   \n",
       " 1      0        67              1560.67              3352.66   \n",
       " 2      0        70  2020-01-31 00:00:00  2025-10-31 00:00:00   \n",
       " 3      0        70              6423.61             116009.4   \n",
       " 4      0        67  2020-01-31 00:00:00  2025-07-31 00:00:00   \n",
       " 5      0        67              1560.67              3352.66   \n",
       " 6      0        67              6423.61             116009.4   \n",
       " 7      0        66  2020-02-29 00:00:00  2025-07-31 00:00:00   \n",
       " \n",
       "                example           unit            role  \\\n",
       " 0  2020-01-31 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " 1              1560.67            USD  feature(level)   \n",
       " 2  2020-01-31 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " 3              9342.23            USD  feature(level)   \n",
       " 4  2020-01-31 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " 5              1560.67            USD  feature(level)   \n",
       " 6              9342.23            USD  feature(level)   \n",
       " 7  2020-02-29 00:00:00  YYYY-MM (EOM)       key(time)   \n",
       " \n",
       "                                     description                      source  \\\n",
       " 0                  End-of-month timestamp (EOM)  Processed (pipeline 02–07)   \n",
       " 1  Monthly gold price (USD), end-of-month close  Processed (pipeline 02–07)   \n",
       " 2                  End-of-month timestamp (EOM)  Processed (pipeline 02–07)   \n",
       " 3   Monthly BTC price (USD), end-of-month close  Processed (pipeline 02–07)   \n",
       " 4                  End-of-month timestamp (EOM)  Processed (pipeline 02–07)   \n",
       " 5                        Merged Gold_USD at EOM  Processed (pipeline 02–07)   \n",
       " 6                         Merged BTC_USD at EOM  Processed (pipeline 02–07)   \n",
       " 7                  End-of-month timestamp (EOM)  Processed (pipeline 02–07)   \n",
       " \n",
       "                                    transform  \n",
       " 0  Monthly EOM; cleaned & filtered 2020–2025  \n",
       " 1  Monthly EOM; cleaned & filtered 2020–2025  \n",
       " 2                   Hourly→EOM monthly close  \n",
       " 3                   Hourly→EOM monthly close  \n",
       " 4                   Hourly→EOM monthly close  \n",
       " 5                   Hourly→EOM monthly close  \n",
       " 6                   Hourly→EOM monthly close  \n",
       " 7                   Hourly→EOM monthly close  ,\n",
       "                                      file  rows  n_cols      start        end  \\\n",
       " 0        gold_monthly_clean_2020_2025.csv    67       1 2020-01-31 2025-07-31   \n",
       " 1         btc_monthly_close_2020_2025.csv    70       1 2020-01-31 2025-10-31   \n",
       " 2   merged_gold_btc_monthly_2020_2025.csv    67       2 2020-01-31 2025-07-31   \n",
       " 3  monthly_returns_gold_btc_2020_2025.csv    66       4 2020-02-29 2025-07-31   \n",
       " \n",
       "    eom_missing  dup_index  \n",
       " 0            5          0  \n",
       " 1            2          0  \n",
       " 2            5          0  \n",
       " 3            6          0  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols, all_ds = [], []\n",
    "for p in FILES:\n",
    "    if p.exists():\n",
    "        cprof, dprof = profile_file(p)\n",
    "        all_cols.append(cprof)\n",
    "        all_ds.append(dprof)\n",
    "\n",
    "data_dict = pd.concat(all_cols, ignore_index=True)\n",
    "dataset_summary = pd.concat(all_ds, ignore_index=True)\n",
    "\n",
    "# (Optional) merge notes manually if you have this file:\n",
    "# create this file if you want to override 'description/unit/role'\n",
    "notes_path = TBL/\"data_dictionary_notes.csv\"   \n",
    "if notes_path.exists():\n",
    "    # minimum columns: file, column, description (plus unit/role if any)\n",
    "    notes = pd.read_csv(notes_path) \n",
    "    data_dict = data_dict.merge(notes, on=[\"file\",\"column\"], how=\"left\", suffixes=(\"\",\"_note\"))\n",
    "    for k in (\"description\",\"unit\",\"role\"):\n",
    "        if f\"{k}_note\" in data_dict.columns:\n",
    "            data_dict[k] = data_dict[f\"{k}_note\"].fillna(data_dict[k])\n",
    "            data_dict.drop(columns=[f\"{k}_note\"], inplace=True)\n",
    "\n",
    "data_dict.head(8), dataset_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7f375",
   "metadata": {},
   "source": [
    "4. Save CSV + Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352e1f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → C:\\Users\\Noveno\\OneDrive\\CA1-BTC-Gold-Correlation\\reports\\tables\\data_dictionary.csv\n",
      "Saved → C:\\Users\\Noveno\\OneDrive\\CA1-BTC-Gold-Correlation\\reports\\tables\\dataset_summary.csv\n",
      "Saved → C:\\Users\\Noveno\\OneDrive\\CA1-BTC-Gold-Correlation\\reports\\tables\\data_dictionary.md\n"
     ]
    }
   ],
   "source": [
    "# Save CSV\n",
    "dict_path = TBL/\"data_dictionary.csv\"\n",
    "sum_path  = TBL/\"dataset_summary.csv\"\n",
    "data_dict.to_csv(dict_path, index=False)\n",
    "dataset_summary.to_csv(sum_path, index=False)\n",
    "print(\"Saved →\", dict_path.resolve())\n",
    "print(\"Saved →\", sum_path.resolve())\n",
    "\n",
    "# Create concise Markdown for reports\n",
    "md_lines = [\"# Data Dictionary (Processed)\\n\"]\n",
    "for f, g in data_dict.groupby(\"file\"):\n",
    "    md_lines.append(f\"\\n## {f}\\n\")\n",
    "    sub = g[[\"column\",\"dtype\",\"unit\",\"role\",\"description\"]].copy()\n",
    "    md_lines.append(sub.to_markdown(index=False))\n",
    "md = \"\\n\".join(md_lines)\n",
    "md_path = TBL/\"data_dictionary.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as fh:\n",
    "    fh.write(md)\n",
    "print(\"Saved →\", md_path.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
